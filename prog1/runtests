#!/bin/bash

# runtests - Run all testcases
#
# Usage: cd into submission directory and run script:
#     ./runtests
#     ./runtests testfile ...
#
# The script takes zero or more test files on the command line.  If tests
# are listed on the command line, only those tests are run.  Otherwise,
# all the tests from the test suite are run.  The first line of each test
# file is a message that is printed when the test fails.  The remainder
# of the file is used as test input.  Test files with file name extension
# ".-d" are used for testing the scanner, all other test files are used
# for testing the pretty printer.
#
# The script assumes that there is a single executable with extension .exe
# in the submission directory.  It runs the executable on the provided test
# inputs.  The script compares the output of the submission to that of the
# reference implementation.  For scanner tests, the output must be identical
# for the test to succeed.  For pretty printer tests, the output is compared
# using both "diff" and "diff -b".  If the comparison with "diff" fails but
# the one with "diff -b" succeeds, it means that the tree was build correctly
# but that the output was formatted incorrectly.
#
# A report on the test runs is generated in file dir-report.txt, where dir
# is the name of the submission directory.
#
# Author: Gerald Baumgartner
# Date:   11/10/2015

project="project1"

solution="/classes/cs4101/cs4101_bau/Csharp-Testing/prog1.soln/SPP.exe"
testdir="/classes/cs4101/cs4101_bau/Csharp-Testing/Tests/$project"

subdir="`pwd`"
submission="${subdir##*/}"
student="${submission%%-*}"

if ls *.java 1> /dev/null 2>&1; then
    exe="/usr/java/java8/bin/java -cp $subdir Main"
else
    exe="$subdir/`ls *.exe`"
fi

report="$subdir/${student}-testreport.txt"

if ls tmp 1> /dev/null 2>&1; then
    mv tmp tmp$$
fi

mkdir tmp

cd $testdir

# If command line arguments are provided, use them, otherwise run all tests.
if [ "$*" != "" ]; then
    tests="$*"
else
    tests="`ls *`"
fi

cp -p $tests $subdir/tmp
cd $subdir/tmp


let "nsucc = 0"
let "nform = 0"
let "nfail = 0"
let "nerrs = 0"

echo "Running tests:" > $report

for i in *; do
    if [ "${i%%.-d}" != "$i" ]; then
	# Testing scanner
	opt="-d"
    else
	# Testing pretty-printer
	opt=""
    fi

    tail -n +2 $i | $solution $opt > $i.soln 2> $i.soln.err
    bash -c "ulimit -t 3; tail -n +2 $i | $exe $opt" > $i.out 2> $i.err
    diff --text $i.soln $i.out > $i.diff 2>&1
    diff --text -b $i.soln $i.out > $i.diff-b 2>&1
    diff --text $i.soln.err $i.err > $i.err.diff 2>&1

    if diff --text $i.soln $i.out > /dev/null 2>&1; then
	echo "$i: SUCCESS" >> $report
	let "nsucc = $nsucc + 1"

	if [ -s $i.err.diff ] ; then
	    echo "$i Errors:" >> $report
	    echo "-----" >> $report
	    cat $i.err.diff >> $report
	    echo "-----" >> $report
	    let "nerrs = $nerrs + 1"
	fi
    else
	if diff --text -b $i.soln $i.out > /dev/null 2>&1; then
	    echo "$i: FORMAT" >> $report
	    head -n 1 $i >> $report
	    echo "-----" >> $report
	    cat $i.diff  >> $report
	    echo "-----" >> $report
	    let "nform = $nform + 1"

	    if [ -s $i.err.diff ] ; then
		echo "$i Errors:" >> $report
		echo "-----" >> $report
		cat $i.err.diff >> $report
		echo "-----" >> $report
		let "nerrs = $nerrs + 1"
	    fi
	else
	    echo "$i: FAIL" >> $report
	    head -n 1 $i >> $report
	    echo "-----" >> $report
	    cat $i.diff  >> $report
	    echo "-----" >> $report
	    let "nfail = $nfail + 1"

	    if [ -s $i.err.diff ] ; then
		echo "$i Errors:" >> $report
		echo "-----" >> $report
		cat $i.err.diff >> $report
		echo "-----" >> $report
		let "nerrs = $nerrs + 1"
	    fi
	fi
    fi
done

echo >> $report
echo "$nsucc tests succeeded" >> $report
echo "$nform tests were formatted incorrectly" >> $report
echo "$nfail tests failed" >> $report
echo "$nerrs tests had errors" >> $report

# let "score = 2 * $nsucc + $nform"

# echo >> $report
# echo "Score: $score" >> $report

cd $subdir
